# Parse Cloud Foundry logs from loggregator (syslog)
# see https://github.com/cloudfoundry/loggregator/blob/master/src/loggregator/sinks/syslogwriter/syslog_writer.go#L156

if [@type] in ["syslog", "relp"] and [syslog_program] == "doppler" {
# Parse Cloud Foundry logs from doppler (via https://github.com/SpringerPE/firehose-to-syslog)

json {
    source => 'syslog_message'
    add_tag => [ 'cloudfoundry_doppler' ] #This is only added if json parsing is successful
}

if "_jsonparsefailure" in [tags] {

    # Amend the failure tag to match our fail/${addon}/${filter}/${detail} standard
    mutate {
        add_tag => ["fail/cloudfoundry/doppler/jsonparsefailure_of_syslog_message"]
        remove_tag => ["_jsonparsefailure"]
    }

} else {

    date {
        match => [ "time", "ISO8601" ]
    }

    # Replace the unicode newline character \u2028 with \n, which Kibana will display as a new line.  Seems that passing a string with an actual newline in it is the only way to make gsub work
    mutate {
    gsub => [ "msg", '\u2028', "
"
    ]
    }

    if ('RTR' in [source_type]) {
        grok {
            #cf-release > v205 - includes RequestBytesReceived
            match => { 'msg' => '%{HOSTNAME:hostname} - \[(?<time>%{MONTHDAY}/%{MONTHNUM}/%{YEAR}:%{TIME} %{INT})\] \"%{WORD:verb} %{URIPATHPARAM:path} %{PROG:http_spec}\" %{BASE10NUM:status:int} %{BASE10NUM:request_bytes_received:int} %{BASE10NUM:body_bytes_sent:int} \"%{GREEDYDATA:referer}\" \"%{GREEDYDATA:http_user_agent}\" %{HOSTPORT} x_forwarded_for:\"%{GREEDYDATA:x_forwarded_for}\" vcap_request_id:%{NOTSPACE:vcap_request_id} response_time:%{NUMBER:response_time:float} app_id:%{NOTSPACE}' }

            #cf-release <= v205
            match => { 'msg' => '%{HOSTNAME:hostname} - \[(?<time>%{MONTHDAY}/%{MONTHNUM}/%{YEAR}:%{TIME} %{INT})\] \"%{WORD:verb} %{URIPATHPARAM:path} %{PROG:http_spec}\" %{BASE11NUM:status:int} %{BASE10NUM:body_bytes_sent:int} \"%{GREEDYDATA:referer}\" \"%{GREEDYDATA:http_user_agent}\" %{HOSTPORT} x_forwarded_for:\"%{GREEDYDATA:x_forwarded_for}\" vcap_request_id:%{NOTSPACE:vcap_request_id} response_time:%{NUMBER:response_time:float} app_id:%{NOTSPACE}' }
            overwrite => [ "time" ]
            tag_on_failure => [ 'fail/cloudfoundry/doppler/RTR' ]
        }

        if !("fail/cloudfoundry/doppler/RTR" in [tags]) {
            date {
                match => [ "time", "dd/MM/y:HH:mm:ss Z" ]
            }
            if [x_forwarded_for] {
                mutate {
                    gsub => ["x_forwarded_for","[\s\\"]",""] # remove quotes and whitespace
                    split => ["x_forwarded_for", ","] # format is client, proxy1, proxy2 ...
                }

            mutate {
                add_field => ["remote_addr", "%{x_forwarded_for[0]}"]
            }

            if ([remote_addr] =~ /([0-9]{1,3}\.){3}[0-9]{1,3}/) {
                geoip {
                    source => "remote_addr"
                }
            }
            }

            mutate {
                remove_field => [ "msg" ]
            }
        }
    }

    #Ensure that we always have an event_type, in prep for adding metrics
    if ![event_type] {
        mutate {
            add_field => [ "event_type", "LogMessage" ]
        }
    }

    mutate {
        remove_field => "@type"
    }

    mutate {
        add_field => [ "@type", "cloudfoundry_doppler" ]
        rename => [ "syslog_message", "@message" ]
        remove_field => "time"
        remove_field => "syslog_severity_code"
        remove_field => "syslog_facility_code"
        remove_field => "syslog_facility"
        remove_field => "syslog_severity"
        remove_field => "syslog_pri"
        remove_field => "syslog_program"
        remove_field => "syslog_pid"
    }
}

} else if [@type] in ["syslog", "relp"] and [@source.host] == "loggregator" {
# Parse Cloud Foundry logs from loggregator (syslog)
# see https://github.com/cloudfoundry/loggregator/blob/master/src/loggregator/sinks/syslogwriter/syslog_writer.go#L156

mutate {
    add_field => [ "tmp_syslog_procid" ,"%{syslog_procid}" ]
}

# [App/0] => [App, 0]
mutate {
    gsub => [ "tmp_syslog_procid", "[\[\]]", "" ]
    split => [ "tmp_syslog_procid", "/" ]
    add_field => [ "source_type" ,"%{[tmp_syslog_procid][0]}"  ]
    add_field => [ "source_instance" ,"%{[tmp_syslog_procid][1]}"  ]
    remove_field => [ "tmp_syslog_procid" ]
}

# For source types with no instance number, remove the field
if [source_instance] == "%{[tmp_syslog_procid][1]}" {
    mutate {
    remove_field => [ "source_instance" ]
    }
}

#If it looks like JSON, it must be JSON...
if [syslog_message] =~ /^\s*{".*}\s*$/ {
    json {
        source => "syslog_message"
    }
    # @todo seems like some messages have @timestamp in them? seems ci-specific
    date {
        match => [ "@timestamp", "ISO8601" ]
    }
} else {
    mutate {
        add_field => [ "message", "%{syslog_message}" ]
    }
    if [message] == "-" {
        mutate {
            remove_field => "message"
        }
    }
}
mutate {
    rename => [ "syslog_program", "@source.app_id" ]
}
mutate {
    add_tag => "cloudfoundry_loggregator"
    remove_field => "syslog_facility"
    remove_field => "syslog_facility_code"
    remove_field => "syslog_message"
    remove_field => "syslog_severity"
    remove_field => "syslog_severity_code"
    remove_field => "syslog5424_ver"
    remove_field => "syslog6587_msglen"
}

} else if [@type] in ["syslog", "relp"] and [syslog_program] == "vcap.uaa" {
# Parse Cloud Foundry logs from syslog_aggregator

grok {
    match => { "syslog_message" => "\[job=%{NOTSPACE:jobname}%{SPACE}index=%{NOTSPACE:jobindex}\]%{SPACE}\[%{TIMESTAMP_ISO8601:uaa_timestamp}\]%{SPACE}uaa%{SPACE}-%{SPACE}%{NUMBER:pid:int}%{SPACE}\[%{DATA:thread_name}\]%{SPACE}....%{SPACE}%{LOGLEVEL:@loglevel}%{SPACE}---%{SPACE}Audit:%{SPACE}%{WORD:audit_event_type}%{SPACE}\('%{DATA:audit_event_data}'\):%{SPACE}principal=%{DATA:audit_event_principal},%{SPACE}origin=\[%{DATA:audit_event_origin}\],%{SPACE}identityZoneId=\[%{DATA:audit_event_identity_zone_id}\]" }
    tag_on_failure => [
        "fail/cloudfoundry/uaa-audit"
    ]
    add_tag => "uaa-audit"
}

if !("fail/cloudfoundry/uaa-audit" in [tags]) {
    date {
        match => [ "uaa_timestamp", "ISO8601" ]
    remove_field => "uaa_timestamp"
    }

    if "PrincipalAuthenticationFailure" == [audit_event_type] {
        mutate {
            add_field => { "audit_event_remote_address" => "%{audit_event_origin}" }
    }
    }

    if [audit_event_origin] =~ /remoteAddress=/ {
        grok {
            match => { "audit_event_origin" => "remoteAddress=%{IP:audit_event_remote_address}" }
        }
    }

    if [audit_event_remote_address] {
    geoip {
        source => "audit_event_remote_address"
    }
    }

    mutate {
        replace => { "@type" => "uaa-audit" }

    remove_field => "syslog_pri"
    remove_field => "syslog_facility"
    remove_field => "syslog_facility_code"
    remove_field => "syslog_message"
    remove_field => "syslog_severity"
    remove_field => "syslog_severity_code"

        rename => { "syslog_program" => "[@source][syslog_program]" }
        rename => { "@source.host"   => "[@source][host]" }
        rename => { "jobname"        => "[@source][job][name]" }
        rename => { "jobindex"       => "[@source][job][index]" }

        split =>  { "audit_event_origin" => ", " }
    }
}

} else if "collector" in [tags] {
# Parse Cloud Foundry Collector

mutate {
    remove_field => [ "level", "facility", "file", "line", "version", "source_host" ]
        rename => { "attributes" => "@source" }

}

mutate {
    add_field => { "[@source][host]" => "%{host}" }
    add_field => { "[@source][job_name]" => "%{[@source][job]}/%{[@source][index]}" }
}

mutate {
    remove_field => [ "host", "[@source][name]" ]
}

} else if [@type] in ["syslog", "relp"] and [syslog_program] =~ /vcap\..*/ {
# Parse Cloud Foundry logs from syslog_aggregator

grok {
    match => { "syslog_message" => "(?:\[job=%{NOTSPACE:@job.name}|-) +(?:index=%{NOTSPACE:@job.index}\]|-) +%{GREEDYDATA:_message_json} *" }
    tag_on_failure => [
        "_grokparsefailure-cf-vcap"
    ]
}

if !("_grokparsefailure-cf-vcap" in [tags]) {
    kv {
        source => "msgdata"
        field_split => " "
        target => "msgdata"
    }

    #If it looks like JSON, it must be JSON...
    if [_message_json] =~ /^\s*{".*}\s*$/ {
        json {
            source => "_message_json"
            remove_field => "_message_json"
        }
    } else {
        mutate {
            rename => [ "_message_json", "_message_invalid_json" ]
        }
    }

    mutate {
        rename => [ "syslog_program", "@shipper.name" ]
        replace => [ "@job.host", "%{@source.host}" ]
        gsub => [
            "@shipper.name", "\.", "_",
            "@job.name", "\.", "_"
        ]
    }

    if [source] == "NatsStreamForwarder" {
        #If it looks like JSON, it must be JSON...
        if [data][nats_message] =~ /^\s*{".*}\s*$/ {
            json {
                source => "[data][nats_message]"
                target => "nats_message"
            }
            mutate {
                remove_field => "[data][nats_message]"
            }
        } else {
            mutate {
                rename => [ "[data][nats_message]", "_nats_invalid_json" ]
            }
        }
    }

    mutate {
        add_tag => "cloudfoundry_vcap"
        replace => [ "@shipper.priority", "%{syslog_pri}" ]
        replace => [ "@shipper.name", "%{@shipper.name}_%{@type}" ]
        replace => [ "@type", "%{@type}_cf" ]
    }

    mutate {
        remove_field => "syslog_facility"
        remove_field => "syslog_facility_code"
        remove_field => "syslog_message"
        remove_field => "syslog_severity"
        remove_field => "syslog_severity_code"
    }
}
}
# Short term fix (aka definitive solution), drop the data field to avoid
# error inserting in ES.
# If not, we get the error: failed action with response of 400
if [@shipper.name] == "vcap_routing-api_relp" {
mutate {
    remove_field => [ "data" ]
}
}

